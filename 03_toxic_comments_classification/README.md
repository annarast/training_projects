**Описание задачи**  

Разработать модель классификации комментариев на токсичные и нетоксичные.  
Требования к модели: значение метрики f1 на тестовой выборке не меньше 0,75.   

**Источник данных** 

База комментариев, размеченных на токсичные и не токсичные.

**Ключевые шаги в решении задачи:**

1. Анализ данных с целью определения пригодности данных для обучения.  
2. Подготовка данных к обучению (очистка от специальных символов и знаков препинания, разделение на обучающую и тестовую выборки, лемматизация, векторизация).  
3. Выбор моделей для обучения, определение диапазонов гиперпараметров для последующего подбора оптимальных.  
4. Обучение моделей с подбором гиперпараметров с использованием Pipeline для избежания утечки данных на кросс-валидации, подбор гиперпараметров и расчет метрики f1 с помощью GridSearchCV.  
5. Анализ полученных на разных моделях результатов, выбор лучшей модели с лучшими гиперпараметрами по максимальному значению метрики f1 и проверка её работоспособности на тестовой выборке.

**Результат**

 Исходные данные были подготовлены следующими способами:  
* только очистка от специальных символов и знаков препинания и векторизация с помощью алгоритма TF-IDF (на всей выборке);  
* очистка от специальных символов и знаков препинания, лемматизация и векторизация с помощью алгоритма TF-IDF (на части выборки);
* очистка от специальных символов и знаков препинания, лемматизация и векторизация с помощью предобученной модели BERT (на части выборки).  

Для классификации комментариев на токсичные и нетоксичные были построены модели машинного обучения  на основе алгоритмов Logistic Regression, Random Forest, XGBoost, Catboost.   
Максимальное значение метрики f1 (0.762) было получено с помощью модели на базе Logistic Regression с гиперпараметрами class_weight = 'balanced', C=13, penalty='l2' на всей выборке, очищенной от специальных символов и знаков препинания.  
На тестовой выборке величина метрики составила 0.756, что соответствует заданному условию.   
Данная модель предложена для определения токсичности комментариев. Это позволит в первую очередь реагировать на комментарии, отмеченные как токсичные, и сокращать время их нахождения на сайте. Также потенциально можно автоматизировать процесс модерации и автоматически отклонять комментарии, отмеченные как токсичные при условии увеличения точности классификации.  

**Используемые библиотеки и технологии:**  
* pandas
* numpy
* matplotlib
* seaborn
* spacy
* pytorch
* BERT
* sklearn
* GridSearchCV
* catboost
* xgboost
* random forest
* logistic regression
* TF-IDF
* Pipeline
